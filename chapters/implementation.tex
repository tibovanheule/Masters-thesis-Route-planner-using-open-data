\chapter{Implementation}
\label{chap:implementation}

Originally, the implementation was divided into two parts. We discuss the implementation of \glsfmtshort{raptor} for the browser in \autoref{section:implementation_raptor}. The conversion and download of GTFS data is discussed in \autoref{section:implementation_data_ontology}.


\section{\glsfmtshort{raptor} implementation}\label{section:implementation_raptor}
\subsection{Data usage ofexistingimplemtation}
Sincewestarted from a existing implementation of raptor we did a small research which data was used by the parser/ implementation.

Small description of text files used and how they are transformed.
$
- link = ? (Think footwalks) => Object "transfers" with ke from_stop_id (=origin) -> list
- calendar = calendar.txt => Object "calendars", uses service_id as key
- calendar_date = calendar_dates.txt => Object "dates" with key service id -> object with key date -> row.exception_type === "1" (service exceptions)
- trip = trips.txt => Array "trips"
- stop_time = stop_times.txt => Object "StopTimes" with key_trip id -> list
- transfer = transfers.txt => Object "Interchange" for transfer from and to the same stop. || Object "transfers" with key from_stop_id (=origin) -> list
- stop = stops.txt => Object "stops" with key stop_id
$
\subsubsection{Notused but are in our \glsfmtshort{gtfs}-feed}
\begin{itemize}
    \item feed\_info: information the feed itself.
    \item agency: information about the agency providing the services.
    \item areas: 
    \item translations:
\end{itemize}
\subsection{Unavailable in feed}
\begin{itemize}
    \item shapes (shape of a route, handy for visualizations)
    \item fare\_rules
    \item fare\_attributes
    \item levels
    \item attributions
\end{itemize}

\subsection{small mistakes of the implementation}
\subsubsection{unused information from gtfsfeed}
The algorithm did not use some information but was thereby inferred. For example:
\begin{itemize}
    \item Order of stop points. Each stop point in a sequence was based on its position in the array. Which is not a big problem if the array is correctly sorted. But a \glsfmtshort{gtfs} feed requires each stop point to carry information like their position in the sequence. This is more correct since it supports feeds with incorrectly sorted stop points.
    \item Route id was not used but created from the tripid 
\end{itemize}
\section{GTFS downloader}
Since a GTFS feed is a zip file valid for a certain period, we need a small program to manage all these versions. This led to a Node.js module gtfs-downloader\footnote{Available as GitLab project under the same name}. It provides the file path of the GTFS zip archive that either has been downloaded in the past or is freshly downloaded. So, it also acts like a cache and is more important than it appears, as only the most recent is available on the server. For debugging and experimenting while developing, it is handy that we have some control over the version in use. 

Two sets of functionality are represented in \autoref{fig:gtfsdownloader}. The first is when we already know the version we want to download. We search if it exists in our data folder; if not, we check if it is available on the server for download.

In the other case we want to have the latest version, we send a head request to the server\footnote{Server url is specified in a dot env config}, since we are only interested in the LastModified header. We check if that version is available locally, if not we download the zip file.
\input{tikz/tikz_gtfs_downloader}
\section{Data parser/ontology}\label{section:implementation_data_ontology}
Since most datasets, including the datasets of the NMBS we use, use the \glsfmtshort{gtfs} Data model we decided to write a program to convert \glsfmtshort{gtfs} to the OSLO ontology.

\subsection{Parser}
The initial plan was to reuse the parser, but it used a package called gtfs-stream \cite{noauthor_staecogtfs-stream_2024}. It uses an Readablestream object and creates a pipe stream. 

This package is very good if you want to read a \glsfmtshort{gtfs}-feed, but for converting a feed to a different ontology, the package has one big short coming. Mainly it is not possible to define the order in which the module reads the files. For example if you want to read the trips before stoptimes, this is not possible.

We chose to implement something similar but without the gtfs-stream module. Instead we use the standard csv parser. 
\subsection{comformity of ontology}
\cite{noauthor_conformiteit_nodate}
Conformiteit Applicatieprofielen

Een applicatieprofiel is een specificatie voor gegevensuitwisseling dat bijkomende beperkingen introduceert voor het toepassen van vocabularia. Dergelijke bijkomende beperkingen kunnen de volgende elementen bevatten:

    verfijning van de terminologie (klassen en eigenschappen) consistent met de semantiek uit de betreffende specificaties met een welbepaald gebruik als doel;
    externe terminologie (klassen en eigenschappen) gebruikt voor nieuwe/extra termen die niet in de bestaande vocabularia voorkomen.

Om conform te zijn met dit applicatieprofiel, geldt voor een implementatie dat ze:

    MOET Voor elke klasse steeds de eigenschappen bevatten die als minimum kardinaliteit 1 hebben.
    MAG NIET meer dan 1 instantie bevatten van eigenschappen die 1 als maximum kardinaliteit hebben.
    MAG yerminologie (klassen en eigenschappen) gebruiken op een manier die consistent is met haar semantiek (definitie, gebruik, domein en bereik).
    MAG NIET terminologie van andere gecontroleerde vocabularia gebruiken dan diegene die gedefinieerd wordt in dit applicatieprofiel.
    MAG uitgebreid worden met klassen en eigenschappen van andere datamodellen (vocabularia) die niet overlappen met terminologie uit dit applicatieprofiel.
\input{tikz/tikz_ontology}
\subsection{Nesting}
\subsection{Result}
\subsection{Mistakes in context}
When we first donwloaded the ontology, we noticed it wouldn't work in the json-ld playground. Upon closer inspection we noticed 
$$@type; ""$$
\section{Bringing two worlds together: expirmentation of fragmenting}
%\subsection{first naive idea}
